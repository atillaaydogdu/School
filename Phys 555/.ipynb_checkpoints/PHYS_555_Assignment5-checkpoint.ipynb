{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKczI139PJhV"
   },
   "source": [
    "# Database and Machine Learning Basics\n",
    "\n",
    "**PHYS-555 Winter 2020 - Assignment #5**\n",
    "\n",
    "\n",
    "Copy this notebook, edit and format it as you wish, as long as we can understand you answered the questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0z6ZyNjOb51"
   },
   "source": [
    "## Knowledge Part (50%)\n",
    "\n",
    "You can answer the questions with a notebook cell below each question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iw60nd4rO3lu"
   },
   "source": [
    "1. You are about to run simulations on an HPC cluster which will produce one million outputs. Each output contains:\n",
    "  - a description of the output: date of simulation, number of parameters M, and the value for each parameters (the metadata)\n",
    "  - an array of 100,000 elements representaing the generated synthetic data set for this set of parameters.\n",
    "\n",
    "  Describe briefly how you would store your outputs in such a way you could explore, search and share the results efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IrUQcdMRQ1D"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-kvlRrLRUsX"
   },
   "source": [
    "2. Give a situation where you would you use a NoSQL database document \n",
    "store rather than a traditional single relational (SQL) database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-dpp2XlKu-G"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vth8lN1FR9UX"
   },
   "source": [
    "3. What is the main issue you have to tackle in a distributed database? Explain briefly the difference between a CA and a CP database and when you could choose one vs the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0k3OkowKxQ7"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ML9zsKkySihR"
   },
   "source": [
    "4. You are collecting data from geographically distributed sensors in the ocean. You want to keep GPS coordinates, depth for each sensor, and the pressure, temperature every day. Describe a simple relational data model to store the data (i.e. what are the tables you are creating), so that you can query your data with SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "My2xhOd1KyiB"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRu9_QJLTDmz"
   },
   "source": [
    "5. Where is the query executed when:\n",
    "  - a) you are querying from a python script running on your laptop a table kept in \n",
    "Google BigQuery\n",
    "  - b) you are querying a pandas dataframe from a jupyter session launched from your laptop\n",
    "  - c) you are querying a BigQuery table in a Google Colab session accessed from your laptop browser\n",
    "  - d) you have launched a job from the Compute Canada graham cluster which will query tables in a PostgresQL database on the cedar cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FFzv9t2K0q_"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voWIBnkHTfxK"
   },
   "source": [
    "6. Why do we use three sets (training, validation and test sets) in machine learning training procedures? In other words, what are the differences between validation and test sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6u6cjdqlK110"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGrfWMWNTpcM"
   },
   "source": [
    "7. What are the relationship between maximum likelihood estimation of a linear model and linear model regression used in machine learning software such as scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfUH2iKPK3HV"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7e1jMtMT0nD"
   },
   "source": [
    "8. Why do we normalize (or scale) our data before the training step? Explore the [scikit-learn documentation](https://scikit-learn.org) and find some normalization functions. Should we normalize a data  set for the PCA method? Name a method (or methods) that does not need a normalization step for the training procedure.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rxf95QZ0Ll3z"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oHhvhWeT9Q2"
   },
   "source": [
    "9. Explain very briefly the overfitting problem in machine learning. Give at least one solution to mitigate overfitting. From a Bayesian perspective, how would the Bayes rule relate to overfitting mitigation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyVFaAtgLn2G"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6WpRNisUE8Y"
   },
   "source": [
    "10. Explain how to obtain a cumulative explained variance plot (see the PCA lecture). Explain how PCA can be used to reduce noise in images (image denoising)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptyTUs-qLpMm"
   },
   "source": [
    "<font color='green'>your answer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQzRaqCSUlkR"
   },
   "source": [
    "## Practice Part (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7MyG8AqUpla"
   },
   "source": [
    "The point of this exercise will be to:\n",
    "- retrieve data from BigQuery with selection on the fly\n",
    "- practice your SQL ninja skills\n",
    "- understand data preparation\n",
    "- try kNN and linear models for regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45b_akrbW7Hh"
   },
   "source": [
    "You may want to practice with BigQuery [quick tutorial](https://colab.research.google.com/notebooks/bigquery.ipynb) if you did not get a chance to do so with the quick tutorial.\n",
    "\n",
    "* first login to Google, and go to the Google Compute Engine [Cloud Resource Manager](https://console.cloud.google.com/cloud-resource-manager) to Create a Cloud Platform project if you do not already have one.\n",
    "* then authenticate the colab notebook to allow access to BigQuery just like in the tutorial linked above.\n",
    "\n",
    "Try to make a project and a dataset. You should have access to the dataset `assign5` associated with the `phys-555-2020` project. You should be able to query both:\n",
    "- the target labels table ID: `phys-555-2020.assign5.targets`\n",
    "- the input features table ID: `phys-555-2020.assign5.inputs`\n",
    "\n",
    "For questions 1-3, expect to spend time reading SQL / BigQuery documentation. For questions 4-7, expect scikit-learn reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVOWdLQkVlhd"
   },
   "source": [
    "1. Explore either with python script or using the BigQuery [console](https://console.cloud.google.com/bigquery) interface the target and labels datasets. How many fields in each of the table? How many NaN does the input table have? Write your SQL queries or your python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "an6hd3cxD3jV"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmRszYj6dHXa"
   },
   "source": [
    "2. Write code using a single SQL query that will return a dataframe with the ID of the sample, 3 associated input features and one target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAL_o2UeFJNj"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnuPY0ecgmkP"
   },
   "source": [
    "3. Create a pandas dataframe with all the input features, and a few target labels, cleaned and scaled. For all the question below, make sure the associated inputs and targets are clean, i.e., have no NaN, and are appropriately scaled. Bonus marks if you clean the data using SQL queries only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tgTCeKaF28G"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufsCDRZ0hDuk"
   },
   "source": [
    "Now you will use k-NN (for regression) and linear regression model to make predictions on your data set. \n",
    "\n",
    "4. Choose a target label (say `tar_2`). Use all feature inputs (`inp_1` to `inp_20`) to predict `tar_2` with linear regression. Examine if you need regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avWKc0c7-OVj"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ygb2gn8I-qcT"
   },
   "source": [
    "5. Find the input (`inp_x`) feature that has no impact (or minimum impact) and the most important one in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7YaAIzo-thD"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4yID8h3d-PJb"
   },
   "source": [
    "6. Use all inputs and do a PCA on the input data. Then use the first 3 components to predict `tar_2`. Compare the results with linear regression with regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhYX6GOu_AYq"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGQ0fL1i_BKV"
   },
   "source": [
    "7. Repeat the same procedure for tar_7 and tar_12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtfOXzcM_dAj"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Is7HgHFChjnU"
   },
   "source": [
    "8. Write code to save your results in a relational database (SQLite or BigQuery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gd3fE1Ss_hsT"
   },
   "outputs": [],
   "source": [
    "# your input"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PHYS-555-Assignment5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
